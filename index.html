<style>

    @import url('https://fonts.googleapis.com/css2?family=Lora&display=swap');
    h1 {
      display: flex;

      font-family: 'Lora', serif;
      text-align: center;
      justify-content: center;
      font-size: 24px;
    }
    .gallery {
  display: grid;
  grid-template-columns: repeat(5, 1fr);
  grid-gap: 10px;
}

.gallery img {
  width: 100%;
  height: 200px;
  object-fit: cover;
  transition: transform 0.2s ease-in-out;
transition: box-shadow 0.2s ease-in-out;

}

.gallery img:hover {
  transform: scale(1.025);
 box-shadow: 0 0 5px rgba(0, 0, 0, 0.5);
}


</style>  

<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Generating Rich, Localized, and  Flexible Captions in Images.">
  <meta name="keywords" content="Flexible, Captions, VQA, Visual Recognition, Visual Dialog">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FlexCap: Generating Rich, Localized, and  Flexible Captions in Images</title>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">FlexCap: Generating Rich, Localized, and  Flexible Captions in Images</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://debidatta.github.io/">Debidatta Dwibedi</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://vidhijain.github.io/">Vidhi Jain</a><sup>1,2</sup>,
              </span>
              <span class="author-block">
                <a href="https://jonathantompson.github.io/">Jonathan Tompson</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://www.robots.ox.ac.uk/~az/">Andrew Zisserman</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a href="https://people.csail.mit.edu/yusuf/">Yusuf Aytar</a><sup>1</sup>
              </span>
              <br>
              &nbsp;&nbsp;&nbsp;<sup>1</sup>Google DeepMind&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>2</sup>Carnegie Mellon University&nbsp;&nbsp;&nbsp;
            </div>

             <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>

              <span class="link-block">
                <a href="https://youtube.com" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <img src="./static/youtube.png" alt="Youtube Link">
                  </span>
                  <span>Video</span>
                </a>
              </span>
            </div>
          </div>
        </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">


    <!-- Abstract. -->              
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
      <h2 class="title is-3 has-text-centered">Abstract</h2>
      <div class="content has-text-justified">
        <p>
          FlexCap is a versatile vision-language model (VLM) capable of generating region-specific descriptions of varying lengths. Trained to produce length-conditioned captions for input bounding boxes, FlexCap empowers the user to control the information density of its output. This allows for descriptions ranging from  concise object labels to detailed captions. This capability has several valuable applications. Firstly, FlexCap demonstrates superior performance in dense captioning tasks on the Visual Genome dataset. Additionally, we introduce FlexCap-LLM, a visual question answering (VQA) system. FlexCap-LLM employs FlexCap to generate localized descriptions which serve as inputs to a large language model (LLM), achieving state-of-the-art zero-shot performance on some VQA datasets. Finally, we qualitatively demonstrate FlexCap's broad applicability in tasks such as image labeling, object attribute recognition, and visual dialog.
          <br><br><br><br>
        </p>
      </div>
       
    </div>
  </div>
  <!-- Abstract. --> 

  <!-- Length Conditioning. -->              
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
      <h2 class="title is-3">Describing Same Region with Different Lengths</h2>
      <div class="content has-text-justified">
        <div class="content has-text-centered">
          <img src="./index_figures/length_conditioning.png"></img>
          <br/>
          <p> 
            FlexCap generates controllably rich localized descriptions for any region in an image. 
            It has the flexibility to produce captions in a controllable manner which allows the full spectrum of valid descriptions to be explored from short object category names to fully-detailed captions. 
          </p>
          <p>
          For results on <strong>length conditioning</strong>, click the button below.
        </p>
        <span class="link-block">
                <a href="./flexcap-length.html" class="internal-link button is-normal is-rounded is-dark">
                  <span>Length Conditioned Captions</span>
                </a>
              </span>
      </div>
        
      </div>
       
    </div>
  </div>
  <!-- Length Conditioning. -->

  <!-- Localization. -->              
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
      <h2 class="title is-3">Describing Different Regions of Same Image</h2>
      <div class="content has-text-centered">
        <img src="./index_figures/spatial_conditioning.png"></img>
<br/>
        <br>
        <p>
          FlexCap can localize salient regions of the image and describing them with natural language sentences. Unlike prior dense captioning works, 
          FlexCap generates more diverse sentences to describe visual content in controllable detail. 
        </p><p>
          Here we present interactive showcase of results for <strong>region captioning</strong>. You can draw a bounding box on the image and we display the best length-conditioned caption generated for the box.
        </p>
        <span class="link-block">
                <a href="./flexcap-spatial.html" class="internal-link button is-normal is-rounded is-dark">
                  <span>Interactive Region-Captioning</span>
                </a>
              </span>
      </div>
       
    </div>
  </div>
  <!-- Localization. -->


  <!-- Object Attributes. -->              
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
      <h2 class="title is-3">Extracting Object Attributes with Prefixes</h2>
      <div class="content has-text-justified">
        <p>FlexCap is trained to generate captions autoregressively, that is, conditioned on the previous tokens. 
          This paradigm enables  <strong>emergent</strong> capabilities to caption region attributes.
          Here we present some of the attributes that FlexCap can generate for regions in an image.
          <list>
          <ul><a href="./flexcap-action.html" class="internal-link is-normal is-rounded">
            <span>Human Action</span>:
          </a>The prompt for extracting actions: <i>The person is _____</i></ul>
          <ul><a href="./flexcap-function.html" class="internal-link is-normal is-rounded">
            <span>Object Use</span>:
          </a>The prompt finding what an object can be used for:  <i>This is used for _____</i> </ul>
          <ul><a href="./flexcap-text.html" class="internal-link is-normal is-rounded">
            <span>Text</span>
          </a>The prompt performing OCR: <i>The sign says _____</i></ul>
          <ul><a href="./flexcap-material.html" class="internal-link  is-normal is-rounded">
            <span>Object Material</span>
          </a>The prompt for extracting material: <i>It is made of _____</i></ul>
          <ul><a href="./flexcap-color.html" class="internal-link is-normal is-rounded">
            <span>Object Color</span>
          </a>The prompt for extracting color: <i>The color is _____</i></ul>
          </list></p>
        <div class="content has-text-centered">
          <img src="./index_figures/attribute_extraction.png"></img>
<br/>
        <p>
          For results on region attribute extraction click the button below.
        </p>
        <span class="link-block">
                <a href="./flexcap-action.html" class="internal-link button is-normal is-rounded is-dark">
                  <span>Human Action</span>
                </a>
                <a href="./flexcap-function.html" class="internal-link button is-normal is-rounded is-dark">
                  <span>Object Use</span>
                </a>
                <a href="./flexcap-text.html" class="internal-link button is-normal is-rounded is-dark">
                  <span>Text</span>
                </a>
              <a href="./flexcap-material.html" class="internal-link button is-normal is-rounded is-dark">
                  <span>Object Material</span>
                </a>
              <a href="./flexcap-color.html" class="internal-link button is-normal is-rounded is-dark">
                  <span>Object Color</span>
                </a>
              </span>
        </div>
      </div>
       
    </div>
  </div>
  <!-- Object Attributes. -->

  <!-- FlexCapLLM. -->              
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
      <h2 class="title is-3">FlexCapLLM</h2>
      <div class="content has-text-justified">
        <div class="content has-text-centered">
          <img src="./index_figures/flexcapllm.png"></img>
      </div>
        
      </div>
       <p>
        Rich localized captions generated by FlexCap can be easily passed onto Large Language Models (LLMs) 
        to enable zero-shot visual question answering.
       </p>
    </div>
  </div>
  <!-- FlexCapLLM. -->

</div>
</section>
</body>
